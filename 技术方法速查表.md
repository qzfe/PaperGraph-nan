# è®ºæ–‡çŸ¥è¯†å›¾è°±ç³»ç»Ÿ - æŠ€æœ¯æ–¹æ³•é€ŸæŸ¥è¡¨

## ğŸ“Š æ ¸å¿ƒåŠŸèƒ½æŠ€æœ¯æ˜ å°„è¡¨

| åŠŸèƒ½æ¨¡å— | ä¸»è¦æŠ€æœ¯ | å…³é”®æ–¹æ³• | æ–‡ä»¶ä½ç½® |
|---------|---------|---------|---------|
| ğŸŒ **å›¾è°±å¯è§†åŒ–** | Neo4j + Cypher | å›¾éå†ã€æ¨¡å¼åŒ¹é… | `app/repositories/neo4j_dao.py` |
| ğŸ“Š **æ•°æ®ç»Ÿè®¡** | SQLAlchemy + MySQL | GROUP BY èšåˆ | `app/repositories/mysql_dao.py` |
| ğŸ“¥ **æ•°æ®å¯¼å‡º** | Celery + Pandas | å¼‚æ­¥ä»»åŠ¡å¤„ç† | `app/tasks/export_tasks.py` |
| âš¡ **ç¼“å­˜ä¼˜åŒ–** | Redis | Cache-Aside æ¨¡å¼ | `app/services/*.py` |
| ğŸ”Œ **APIæ¥å£** | FastAPI | ä¾èµ–æ³¨å…¥ã€PydanticéªŒè¯ | `app/api/v1/*.py` |

---

## 1. å›¾è°±å¯è§†åŒ–åŠŸèƒ½ ğŸŒ

### ä½¿ç”¨æŠ€æœ¯
```
Neo4j 5.14+ â†’ CypheræŸ¥è¯¢è¯­è¨€ â†’ Python Driver â†’ GraphDAO
```

### æ ¸å¿ƒæŸ¥è¯¢æ–¹æ³•

#### â‘  è·å–æ ¹èŠ‚ç‚¹å›¾è°±
```cypher
MATCH (a:Author)-[r1:AUTHORED]->(p:Paper)
OPTIONAL MATCH (a)-[r2:AFFILIATED_WITH]->(o:Organization)
LIMIT 100
RETURN a, p, o, r1, r2
```
**æŠ€æœ¯ç‚¹**: MATCHæ¨¡å¼åŒ¹é…ã€OPTIONAL MATCHå¯é€‰åŒ¹é…ã€LIMITé™åˆ¶

#### â‘¡ å±•å¼€å­èŠ‚ç‚¹ï¼ˆä¸€åº¦å…³ç³»ï¼‰
```cypher
MATCH (n)-[r]-(m)
WHERE id(n) = $node_id
RETURN n, r, m
```
**æŠ€æœ¯ç‚¹**: åŒå‘å…³ç³»æŸ¥è¯¢ã€èŠ‚ç‚¹IDè¿‡æ»¤

#### â‘¢ èŠ‚ç‚¹è¯¦æƒ…æŸ¥è¯¢
```cypher
MATCH (n)
WHERE id(n) = $node_id
RETURN n, labels(n) as labels
```
**æŠ€æœ¯ç‚¹**: å•èŠ‚ç‚¹æŸ¥è¯¢ã€æ ‡ç­¾æå–

#### â‘£ å¸ƒå±€ä½ç½®ä¿å­˜
```cypher
MATCH (n)
WHERE id(n) = $node_id
SET n.layout_x = $x, n.layout_y = $y
```
**æŠ€æœ¯ç‚¹**: èŠ‚ç‚¹å±æ€§æ›´æ–°

### Pythonå®ç°å±‚æ¬¡
```python
APIå±‚: graph.py (FastAPIè·¯ç”±)
    â†“
Serviceå±‚: graph_service.py (ç¼“å­˜é€»è¾‘)
    â†“
DAOå±‚: neo4j_dao.py (CypheræŸ¥è¯¢)
    â†“
Neo4jæ•°æ®åº“
```

---

## 2. æ•°æ®ç»Ÿè®¡åŠŸèƒ½ ğŸ“Š

### ä½¿ç”¨æŠ€æœ¯
```
MySQL 8.0+ â†’ SQLAlchemy ORM â†’ StatisticsDAO â†’ Redisç¼“å­˜
```

### æ ¸å¿ƒç»Ÿè®¡æ–¹æ³•

#### â‘  æŒ‰å¹´ä»½ç»Ÿè®¡è®ºæ–‡æ•°
```python
# SQLAlchemy æŸ¥è¯¢
query = db.query(
    PaperInfo.year,
    func.count(PaperInfo.paper_id).label("count")
).group_by(PaperInfo.year)

# æ·»åŠ è¿‡æ»¤æ¡ä»¶
if start_year:
    query = query.filter(PaperInfo.year >= start_year)

results = query.all()
```
**æŠ€æœ¯ç‚¹**: GROUP BYèšåˆã€åŠ¨æ€è¿‡æ»¤ã€COUNTå‡½æ•°

#### â‘¡ ä½œè€…æ’è¡Œæ¦œ
```python
query = db.query(
    AuthorInfo.author_id,
    AuthorInfo.name,
    AuthorInfo.paper_count,
    AuthorInfo.h_index
).order_by(AuthorInfo.paper_count.desc()).limit(10)
```
**æŠ€æœ¯ç‚¹**: ORDER BYæ’åºã€DESCé™åºã€LIMITé™åˆ¶

#### â‘¢ æœºæ„æ’è¡Œæ¦œ
```python
query = db.query(
    OrganizationInfo.org_id,
    OrganizationInfo.name,
    OrganizationInfo.paper_count
).order_by(OrganizationInfo.paper_count.desc()).limit(10)
```
**æŠ€æœ¯ç‚¹**: å¤šå­—æ®µæŸ¥è¯¢ã€æ’åº

### ç¼“å­˜ç­–ç•¥
```python
# 1. ç”Ÿæˆç¼“å­˜é”®
cache_key = f"stat:{hashlib.md5(json.dumps(params).encode()).hexdigest()}"

# 2. è¯»å–ç¼“å­˜
cached = redis.get(cache_key)
if cached:
    return json.loads(cached)

# 3. æŸ¥è¯¢æ•°æ®åº“
data = dao.query_aggregated(params)

# 4. å†™å…¥ç¼“å­˜ï¼ˆTTL: 1å°æ—¶ï¼‰
redis.setex(cache_key, 3600, json.dumps(data))
```
**æŠ€æœ¯ç‚¹**: MD5å“ˆå¸Œã€TTLè¿‡æœŸã€JSONåºåˆ—åŒ–

---

## 3. æ•°æ®å¯¼å‡ºåŠŸèƒ½ ğŸ“¥

### ä½¿ç”¨æŠ€æœ¯
```
Celery 5.3+ â†’ Redisæ¶ˆæ¯é˜Ÿåˆ— â†’ Pandas â†’ CSV/Excel
```

### å¼‚æ­¥ä»»åŠ¡æµç¨‹

#### â‘  åˆ›å»ºå¯¼å‡ºä»»åŠ¡
```python
# ç”Ÿæˆä»»åŠ¡ID
job_id = f"exp_{uuid.uuid4().hex[:12]}"

# æ’å…¥ä»»åŠ¡è®°å½•ï¼ˆMySQLï¼‰
job = ExportLog(job_id=job_id, status="pending", params=params)
db.add(job)
db.commit()

# è§¦å‘Celeryä»»åŠ¡
export_papers_task.delay(job_id, params)
```
**æŠ€æœ¯ç‚¹**: UUIDç”Ÿæˆã€æ•°æ®åº“äº‹åŠ¡ã€å¼‚æ­¥è§¦å‘

#### â‘¡ Celeryä»»åŠ¡æ‰§è¡Œ
```python
@celery_app.task(bind=True)
def export_papers_task(self, job_id, params):
    # 1. æ›´æ–°çŠ¶æ€ä¸ºrunning
    update_status(job_id, "running")
    
    # 2. æŸ¥è¯¢æ•°æ®
    papers = db.query(PaperInfo).all()
    
    # 3. Pandasç”Ÿæˆæ–‡ä»¶
    df = pd.DataFrame([p.__dict__ for p in papers])
    file_path = f"exports/{job_id}.csv"
    df.to_csv(file_path, index=False, encoding='utf-8-sig')
    
    # 4. æ›´æ–°çŠ¶æ€ä¸ºdone
    update_status(job_id, "done", file_path=file_path)
```
**æŠ€æœ¯ç‚¹**: ä»»åŠ¡è£…é¥°å™¨ã€çŠ¶æ€æœºç®¡ç†ã€Pandaså¯¼å‡º

#### â‘¢ ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
```python
# ä»æ•°æ®åº“æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
job = db.query(ExportLog).filter_by(job_id=job_id).first()
return {
    "job_id": job.job_id,
    "status": job.status,
    "file_path": job.file_path,
    "error_msg": job.error_msg
}
```

#### â‘£ æ–‡ä»¶ä¸‹è½½
```python
from fastapi.responses import FileResponse

@router.get("/download/{job_id}")
async def download_file(job_id: str):
    file_path = get_file_path(job_id)
    return FileResponse(
        path=file_path,
        filename=os.path.basename(file_path),
        media_type="application/octet-stream"
    )
```
**æŠ€æœ¯ç‚¹**: æ–‡ä»¶æµå“åº”ã€Content-Disposition

### Celeryé…ç½®è¦ç‚¹
```python
celery_app.conf.update(
    task_serializer="json",
    broker="redis://localhost:6379/1",     # æ¶ˆæ¯ä»£ç†
    backend="redis://localhost:6379/2",    # ç»“æœå­˜å‚¨
    task_time_limit=3600,                  # è¶…æ—¶1å°æ—¶
    timezone="Asia/Shanghai"
)
```

---

## 4. ç¼“å­˜ä¼˜åŒ–åŠŸèƒ½ âš¡

### ä½¿ç”¨æŠ€æœ¯
```
Redis 7.0+ â†’ Cache-Asideæ¨¡å¼ â†’ ä¸»åŠ¨å¤±æ•ˆç­–ç•¥
```

### ç¼“å­˜æ¨¡å¼ï¼šCache-Asideï¼ˆæ—è·¯ç¼“å­˜ï¼‰

```python
def get_data(key: str):
    """è¯»å–æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # 1. å°è¯•ä»ç¼“å­˜è¯»å–
    cached = redis.get(f"cache:{key}")
    if cached:
        return json.loads(cached)
    
    # 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥æ•°æ®åº“
    data = database.query(key)
    
    # 3. å†™å…¥ç¼“å­˜
    redis.setex(f"cache:{key}", 3600, json.dumps(data))
    
    return data

def update_data(key: str, data: dict):
    """æ›´æ–°æ•°æ®ï¼ˆä¸»åŠ¨å¤±æ•ˆï¼‰"""
    # 1. æ›´æ–°æ•°æ®åº“
    database.update(key, data)
    
    # 2. åˆ é™¤ç¼“å­˜
    redis.delete(f"cache:{key}")
```

### ç¼“å­˜é”®è®¾è®¡è§„èŒƒ

| æ•°æ®ç±»å‹ | é”®æ ¼å¼ | TTL | ç¤ºä¾‹ |
|---------|-------|-----|------|
| æ ¹èŠ‚ç‚¹å›¾è°± | `graph:root:{params_hash}` | 3600s | `graph:root:abc123` |
| å­èŠ‚ç‚¹æ•°æ® | `graph:children:{node_id}` | 1800s | `graph:children:456` |
| èŠ‚ç‚¹è¯¦æƒ… | `graph:node:{node_id}` | 3600s | `graph:node:789` |
| ç»Ÿè®¡ç»“æœ | `stat:{query_hash}` | 3600s | `stat:def456` |

### ç¼“å­˜å¤±æ•ˆç­–ç•¥

**ä¸»åŠ¨å¤±æ•ˆ**ï¼ˆæ•°æ®æ›´æ–°æ—¶ï¼‰:
```python
# ä¿å­˜å¸ƒå±€åæ¸…é™¤ç›¸å…³ç¼“å­˜
keys = redis.keys("graph:root:*")
if keys:
    redis.delete(*keys)
```

**è¢«åŠ¨å¤±æ•ˆ**ï¼ˆTTLè¿‡æœŸï¼‰:
```python
redis.setex(key, 3600, value)  # 1å°æ—¶åè‡ªåŠ¨è¿‡æœŸ
```

---

## 5. APIæ¥å£åŠŸèƒ½ ğŸ”Œ

### ä½¿ç”¨æŠ€æœ¯
```
FastAPI 0.104.1 â†’ PydanticéªŒè¯ â†’ ä¾èµ–æ³¨å…¥ â†’ å¼‚æ­¥å¤„ç†
```

### æ ¸å¿ƒæŠ€æœ¯ç‚¹

#### â‘  è·¯ç”±å®šä¹‰
```python
router = APIRouter(prefix="/graph", tags=["å›¾è°±å±•ç¤º"])

@router.get("/root", response_model=GraphResponse, summary="è·å–æ ¹èŠ‚ç‚¹")
async def get_root_graph(
    limit: int = Query(100, ge=1, le=1000, description="èŠ‚ç‚¹æ•°é‡")
):
    ...
```
**æŠ€æœ¯ç‚¹**: è·¯ç”±è£…é¥°å™¨ã€Queryå‚æ•°éªŒè¯ã€å“åº”æ¨¡å‹

#### â‘¡ ä¾èµ–æ³¨å…¥
```python
def get_graph_service():
    """ä¾èµ–å·¥å‚å‡½æ•°"""
    neo4j_session = next(get_neo4j_session())
    redis_client = get_redis_client()
    dao = GraphDAO(neo4j_session)
    return GraphService(dao, redis_client)

@router.get("/root")
async def get_root(
    service: GraphService = Depends(get_graph_service)  # ä¾èµ–æ³¨å…¥
):
    result = service.get_root({})
    return result
```
**æŠ€æœ¯ç‚¹**: Dependsä¾èµ–æ³¨å…¥ã€è‡ªåŠ¨èµ„æºç®¡ç†

#### â‘¢ Pydanticæ•°æ®éªŒè¯
```python
class StatisticsQueryRequest(BaseModel):
    metric: str = Field(..., description="æŒ‡æ ‡åç§°")
    start_year: Optional[int] = Field(None, ge=1900, le=2100)
    end_year: Optional[int] = Field(None, ge=1900, le=2100)
    limit: int = Field(100, ge=1, le=1000)
    
    @validator('end_year')
    def check_year_range(cls, v, values):
        """è‡ªå®šä¹‰éªŒè¯ï¼šç»“æŸå¹´ä»½å¿…é¡»å¤§äºèµ·å§‹å¹´ä»½"""
        if 'start_year' in values and v < values['start_year']:
            raise ValueError('end_year must be greater than start_year')
        return v
```
**æŠ€æœ¯ç‚¹**: Fieldå­—æ®µå®šä¹‰ã€validatorè‡ªå®šä¹‰éªŒè¯

#### â‘£ å…¨å±€å¼‚å¸¸å¤„ç†
```python
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    logger.error(f"å…¨å±€å¼‚å¸¸: {exc}")
    return JSONResponse(
        status_code=500,
        content={"code": 500, "message": "æœåŠ¡å™¨é”™è¯¯"}
    )
```

#### â‘¤ CORSé…ç½®
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## 6. æ•°æ®åº“è¿æ¥ç®¡ç† ğŸ”—

### MySQLè¿æ¥æ± 
```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine(
    mysql_url,
    pool_pre_ping=True,      # è¿æ¥å‰æ£€æŸ¥
    pool_size=10,            # è¿æ¥æ± å¤§å°
    max_overflow=20,         # æœ€å¤§æº¢å‡ºè¿æ¥
    echo=settings.DEBUG      # SQLæ—¥å¿—
)

SessionLocal = sessionmaker(bind=engine)

def get_db():
    """æ•°æ®åº“ä¼šè¯ä¾èµ–"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```
**æŠ€æœ¯ç‚¹**: è¿æ¥æ± ç®¡ç†ã€ä¼šè¯è‡ªåŠ¨å…³é—­

### Neo4jè¿æ¥ç®¡ç†
```python
from neo4j import GraphDatabase

class Neo4jConnection:
    def __init__(self):
        self._driver = None
    
    def connect(self):
        if self._driver is None:
            self._driver = GraphDatabase.driver(
                settings.NEO4J_URI,
                auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD)
            )
        return self._driver
    
    def get_session(self):
        return self._driver.session()
```
**æŠ€æœ¯ç‚¹**: å•ä¾‹æ¨¡å¼ã€å»¶è¿Ÿåˆå§‹åŒ–

### Redisè¿æ¥ç®¡ç†
```python
import redis

redis_client = redis.Redis(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    db=settings.REDIS_DB,
    decode_responses=True  # è‡ªåŠ¨è§£ç ä¸ºå­—ç¬¦ä¸²
)
```

---

## 7. é…ç½®ç®¡ç† âš™ï¸

### Pydantic Settings
```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    APP_NAME: str = "è®ºæ–‡çŸ¥è¯†å›¾è°±ç³»ç»Ÿ"
    DEBUG: bool = True
    MYSQL_PASSWORD: str
    
    @property
    def mysql_url(self) -> str:
        """åŠ¨æ€è®¡ç®—å±æ€§"""
        return f"mysql+pymysql://{self.MYSQL_USER}:{self.MYSQL_PASSWORD}@{self.MYSQL_HOST}/{self.MYSQL_DATABASE}"
    
    class Config:
        env_file = ".env"
        case_sensitive = True
```
**æŠ€æœ¯ç‚¹**: ç¯å¢ƒå˜é‡è¯»å–ã€ç±»å‹éªŒè¯ã€åŠ¨æ€å±æ€§

---

## 8. æ—¥å¿—ç³»ç»Ÿ ğŸ“

### Logurué…ç½®
```python
from loguru import logger

# æ§åˆ¶å°è¾“å‡ºï¼ˆå½©è‰²ï¼‰
logger.add(
    sys.stdout,
    format="<green>{time}</green> | <level>{level}</level> | {message}",
    level="DEBUG"
)

# æ–‡ä»¶è¾“å‡ºï¼ˆæŒ‰å¤©è½®è½¬ï¼‰
logger.add(
    "logs/app_{time:YYYY-MM-DD}.log",
    rotation="00:00",      # æ¯å¤©00:00è½®è½¬
    retention="30 days",   # ä¿ç•™30å¤©
    level="INFO"
)

# ä½¿ç”¨
logger.info("ä¿¡æ¯æ—¥å¿—")
logger.error("é”™è¯¯æ—¥å¿—")
logger.debug("è°ƒè¯•æ—¥å¿—")
```

---

## 9. æ•°æ®æ¨¡å‹è®¾è®¡ ğŸ“

### MySQLè¡¨è®¾è®¡ç‰¹ç‚¹

```python
class PaperInfo(Base):
    __tablename__ = "paper_info"
    
    paper_id = Column(String(64), primary_key=True)
    title = Column(String(512), nullable=False)
    
    # è‡ªåŠ¨æ—¶é—´æˆ³
    created_at = Column(DateTime, server_default=func.now())
    updated_at = Column(DateTime, server_default=func.now(), 
                       onupdate=func.now())
    
    # å¤–é”®
    org_id = Column(String(64), ForeignKey("organization_info.org_id"))
```
**æŠ€æœ¯ç‚¹**: ORMæ˜ å°„ã€è‡ªåŠ¨æ—¶é—´æˆ³ã€å¤–é”®çº¦æŸ

### Neo4jå›¾æ¨¡å‹
```
èŠ‚ç‚¹æ ‡ç­¾:
- Paper (id, title, year, venue, doi, keywords, citation_count)
- Author (id, name, h_index, orcid, email)
- Organization (id, name, country, abbreviation, rank_score)

å…³ç³»ç±»å‹:
- AUTHORED (order, is_corresponding)
- AFFILIATED_WITH
- CITES (weight)
```

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯æ€»ç»“

| å±‚æ¬¡ | ä¼˜åŒ–æŠ€æœ¯ | æ•ˆæœ |
|-----|---------|------|
| **æ•°æ®åº“** | ç´¢å¼•ã€è¿æ¥æ± ã€æŸ¥è¯¢ä¼˜åŒ– | å‡å°‘æŸ¥è¯¢æ—¶é—´ |
| **ç¼“å­˜** | Redisç¼“å­˜ã€TTLç­–ç•¥ | é™ä½æ•°æ®åº“å‹åŠ› |
| **API** | å¼‚æ­¥å¤„ç†ã€è¯·æ±‚é™æµ | æå‡å¹¶å‘èƒ½åŠ› |
| **ä»»åŠ¡** | Celeryå¼‚æ­¥ã€é˜Ÿåˆ—ä¼˜å…ˆçº§ | å¤„ç†è€—æ—¶ä»»åŠ¡ |

---

## ğŸ“š å…³é”®æŠ€æœ¯æ–‡æ¡£é“¾æ¥

- **FastAPI**: https://fastapi.tiangolo.com/
- **SQLAlchemy**: https://docs.sqlalchemy.org/
- **Neo4j Cypher**: https://neo4j.com/docs/cypher-manual/
- **Celery**: https://docs.celeryq.dev/
- **Redis**: https://redis.io/docs/
- **Pydantic**: https://docs.pydantic.dev/

---

**æ€»ç»“**: è¿™æ˜¯ä¸€ä¸ªé‡‡ç”¨ç°ä»£æŠ€æœ¯æ ˆå’Œæœ€ä½³å®è·µçš„ä¼ä¸šçº§åº”ç”¨ï¼âœ¨

